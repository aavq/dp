Отличный раздел, тут как раз хочется опираться не на «примерные» значения, а на фактические requests/limits и QoS из кластеров.

Ниже — только **read-only** команды и немного скриптов, с пояснениями.

Буду использовать переменные:

```bash
CTX=your-cluster-context      # kube-context кластера
NS_ISTIO=istio-d              # namespace control plane
NS_GW=sm-gateways             # namespace gateways
```

Везде добавляй `--context="$CTX"`.

---

## 1. `istiod`: реальные requests/limits и QoS

### 1.1. Посмотреть Deployment `istiod`

```bash
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o wide
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o yaml > cluster-$CTX-istiod-deploy.yaml
```

**Пояснение:**

* `get deploy -o wide` сразу покажет масштабирование (реплики) и ноды.
* `-o yaml` сохраняет полный манифест, где в `spec.template.spec.containers[].resources` лежат requests/limits по CPU и памяти.
* Этот YAML можно хранить рядом с документацией как «снимок» состояния кластера.

---

### 1.2. Вытащить только блок ресурсов по контейнерам `istiod`

Если можно использовать `jq`:

```bash
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o json \
  | jq '.spec.template.spec.containers[] | {name, resources}'
```

Без `jq` — через `jsonpath`:

```bash
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" \
  -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{"\n  requests: "}{.resources.requests}{"\n  limits: "}{.resources.limits}{"\n\n"}{end}'
```

**Пояснение:**

* Эти команды ничего не меняют, только читают Deployment.
* Выводом можно сразу заполнять таблицу:

  | Component | CPU request | CPU limit | Mem request | Mem limit |
  | --------- | ----------- | --------- | ----------- | --------- |
  | istiod    | …           | …         | …           | …         |

---

### 1.3. Проверить фактический QoS у Pod’ов `istiod`

```bash
kubectl --context="$CTX" get pods -n "$NS_ISTIO" -l app=istiod \
  -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.qosClass}{"\n"}{end}'
```

**Пояснение:**

* Kubernetes автоматически присваивает Pod’ам класс QoS (`Guaranteed`, `Burstable`, `BestEffort`) исходя из requests/limits всех контейнеров.
* Здесь мы проверяем **фактический** QoS (как его видит Kube), чтобы честно написать в документации, например:

  * «istiod Pods имеют QoS `Burstable`»,
    а не просто «планируется Guaranteed».

---

## 2. Gateways: `istio-ingressgateway` и `istio-egressgateway`

### 2.1. Посмотреть Deployments и ресурсы

```bash
# Ingress
kubectl --context="$CTX" get deploy istio-ingressgateway -n "$NS_GW" -o wide
kubectl --context="$CTX" get deploy istio-ingressgateway -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-ingress-deploy.yaml

# Egress
kubectl --context="$CTX" get deploy istio-egressgateway -n "$NS_GW" -o wide
kubectl --context="$CTX" get deploy istio-egressgateway -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-egress-deploy.yaml
```

**Пояснение:**

* Аналогично `istiod`: сюда смотрим, чтобы понять, какие requests/limits выставлены для Envoy gateway’ев.
* В YAML в `spec.template.spec.containers[]` будет контейнер `istio-proxy` — именно его ресурсы надо использовать в таблице.

---

### 2.2. Вытащить ресурсы по контейнерам gateway’ев

```bash
# Ingress
kubectl --context="$CTX" get deploy istio-ingressgateway -n "$NS_GW" -o json \
  | jq '.spec.template.spec.containers[] | {name, resources}'

# Egress
kubectl --context="$CTX" get deploy istio-egressgateway -n "$NS_GW" -o json \
  | jq '.spec.template.spec.containers[] | {name, resources}'
```

Если `jq` нельзя — аналогично через `jsonpath`.

**Пояснение:**

* Так ты увидишь, совпадает ли реальность с примером из документации (`500m/2 vCPU, 512Mi/2Gi` и т.п.).
* Если есть второй контейнер (sidecar для метрик, init-контейнер), у него тоже могут быть ресурсы — это тоже можно описать, если важно.

---

### 2.3. QoS классы для gateway Pod’ов

```bash
kubectl --context="$CTX" get pods -n "$NS_GW" \
  -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.qosClass}{"\n"}{end}' \
  | grep istio-ingressgateway

kubectl --context="$CTX" get pods -n "$NS_GW" \
  -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.qosClass}{"\n"}{end}' \
  | grep istio-egressgateway
```

**Пояснение:**

* Здесь интересно увидеть, отличаются ли QoS ingress и egress gateway от control-plane (например, ingress — `Guaranteed`, остальное — `Burstable`).

---

## 3. Sidecar per workload: ресурсы и QoS

Тут два подхода:

1. **По конкретным Pod’ам** — посмотреть, как настроен istio-proxy в реальной нагрузке.
2. **По шаблону инжекции** — посмотреть, какие значения задаёт Istio по умолчанию при injection.

### 3.1. Найти «типовой» Pod с sidecar’ом и посмотреть ресурсы

```bash
# Пример: ищем любой pod с аннотацией istio-proxy как контейнером
kubectl --context="$CTX" get pods -A \
  -o jsonpath='{range .items[*]}{.metadata.namespace}{"/"}{.metadata.name}{"\t"}{range .spec.containers[*]}{.name}{" "}{end}{"\n"}{end}' \
  | grep istio-proxy | head -n 10
```

Выбери один из Pod’ов и подставь его:

```bash
NS_APP=<namespace>
POD_APP=<pod-name>

# Ресурсы по всем контейнерам в Pod'е (включая istio-proxy)
kubectl --context="$CTX" get pod "$POD_APP" -n "$NS_APP" -o jsonpath='{.spec.containers[*].name}{"\n"}{.spec.containers[*].resources}'
```

Или нагляднее через `jq`:

```bash
kubectl --context="$CTX" get pod "$POD_APP" -n "$NS_APP" -o json \
  | jq '.spec.containers[] | {name, resources}'
```

**Пояснение:**

* Здесь ты видишь **фактические** requests/limits istio-proxy для конкретного рабочего Pod’а.
* Можно сделать пару выборок по разным namespaces (критичные сервисы, обычные сервисы, batch), чтобы понять, одинаковый ли ресурсный профиль sidecar для всех.

---

### 3.2. Сводка QoS по Pod’ам с sidecar’ом

Чтобы увидеть, как выглядит QoS для приложений в mesh vs вне mesh:

```bash
# Все Pod'ы, где есть контейнер istio-proxy, с QoS
kubectl --context="$CTX" get pods -A -o json \
  | jq -r '.items[]
    | select(.spec.containers[].name=="istio-proxy")
    | "\(.metadata.namespace)/\(.metadata.name)\t\(.status.qosClass)"' \
  > cluster-$CTX-istio-sidecar-pods-qos.txt
```

Если `jq` нельзя — можно два шага: сначала список Pod’ов с `istio-proxy` (как выше), потом по каждому вызвать `kubectl get pod <pod> -o jsonpath=...`.

**Пояснение:**

* По этому файлу легко понять, сколько Pod’ов с sidecar’ом имеют `Guaranteed` vs `Burstable`.
* В документации можно сделать вывод:
  «Большинство workloads в mesh имеют QoS `Burstable` с такими-то ресурсами sidecar…».

---

### 3.3. Шаблон инжекции (какие ресурсы прописаны по умолчанию)

Если вы используете IstioOperator (Helm/ArgoCD) — настройки ресурсов sidecar’а часто задаются там.

Если injection идёт через ConfigMap:

```bash
kubectl --context="$CTX" get configmap -n "$NS_ISTIO" \
  | grep -i inject

kubectl --context="$CTX" get configmap istio-sidecar-injector -n "$NS_ISTIO" -o yaml \
  > cluster-$CTX-istio-sidecar-injector.yaml
```

**Пояснение:**

* В ConfigMap (или в соответствующем IstioOperator CR) есть шаблон Pod’а для injection, и там — block `resources:` для istio-proxy.
* Это «задуманные» (intended) значения, а в Pods — «фактические» (после override’ов).

---

## 4. Node-level: CPUManagerPolicy / TopologyManagerPolicy

Это уже не из Kubernetes API, а из конфигурации kubelet на нодах. Если у тебя есть root-доступ к нодам (а он у тебя есть, судя по другим сообщениям), можно:

На каждой ноде:

```bash
sudo cat /var/lib/kubelet/config.yaml | egrep 'cpuManagerPolicy|topologyManagerPolicy|reservedSystemCPUs'
```

или, если конфиг в другом месте:

```bash
ps aux | grep kubelet
# посмотреть аргумент --config=/путь/к/config.yaml
sudo cat /путь/к/config.yaml | egrep 'cpuManagerPolicy|topologyManagerPolicy'
```

**Пояснение:**

* Так ты увидишь, используются ли `cpuManagerPolicy: static` и какой `topologyManagerPolicy` выставлен (`best-effort`, `restricted`, `single-numa-node` и т.п.).
* В документации можно честно написать:

  * «На нодах, куда schedulится istio-ingressgateway, kubelet настроен с …».
* Здесь очень важно **ничего не править**, только `cat`/`egrep`.

---

## 5. Мини-скрипт для генерации черновика таблицы Resource model

Небольшой скрипт, который собирает requests/limits для `istiod` и gateways и выводит строки в CSV (который легко вставить в Markdown-таблицу):

```bash
#!/usr/bin/env bash
set -euo pipefail

CTX="$1"
NS_ISTIO=istio-d
NS_GW=sm-gateways

echo "component,namespace,container,cpu_request,cpu_limit,mem_request,mem_limit,qos"

# Функция печати строк для Deployment
print_deploy() {
  local ns="$1"
  local dep="$2"
  local comp="$3"

  kubectl --context="$CTX" get deploy "$dep" -n "$ns" -o json \
    | jq -r --arg comp "$comp" --arg ns "$ns" '
      .spec.template.spec.containers[] as $c
      | {
          component: $comp,
          namespace: $ns,
          container: $c.name,
          cpu_request: ($c.resources.requests.cpu // "none"),
          cpu_limit: ($c.resources.limits.cpu // "none"),
          mem_request: ($c.resources.requests.memory // "none"),
          mem_limit: ($c.resources.limits.memory // "none")
        }
      | "\(.component),\(.namespace),\(.container),\(.cpu_request),\(.cpu_limit),\(.mem_request),\(.mem_limit)"'
}

# istiod
print_deploy "$NS_ISTIO" istiod "istiod" \
  | while IFS=, read -r comp ns container cpu_req cpu_lim mem_req mem_lim; do
      qos=$(kubectl --context="$CTX" get pods -n "$NS_ISTIO" -l app=istiod -o json \
        | jq -r '.items[0].status.qosClass')
      echo "$comp,$ns,$container,$cpu_req,$cpu_lim,$mem_req,$mem_lim,$qos"
    done

# ingress и egress gateways
for DEP in istio-ingressgateway istio-egressgateway; do
  comp="$DEP"
  print_deploy "$NS_GW" "$DEP" "$comp" \
    | while IFS=, read -r comp ns container cpu_req cpu_lim mem_req mem_lim; do
        qos=$(kubectl --context="$CTX" get pods -n "$NS_GW" -l app="$DEP" -o json \
          | jq -r '.items[0].status.qosClass')
        echo "$comp,$ns,$container,$cpu_req,$cpu_lim,$mem_req,$mem_lim,$qos"
      done
done
```

Запуск:

```bash
./istio-resources-csv.sh your-cluster-context > cluster-your-cluster-context-istio-resources.csv
```

**Пояснение:**

* Скрипт только читает объекты через `kubectl`, ничего не меняет.
* На выходе — CSV с колонками:

  * `component, namespace, container, cpu_request, cpu_limit, mem_request, mem_limit, qos`
* Этот CSV можно:

  * открыть в Excel,
  * привести в красивую Markdown-таблицу,
  * сравнить с «идеальной» таблицей из документации.

---

Если потребуется, можем потом на основе реального вывода (без секретных деталей) сформировать уже **готовую Resource model-таблицу** и текстовое описание: какие компоненты сейчас `Burstable`, где не заданы limits, где стоит смысл поднять/опустить requests.
