Супер, это как раз хороший раздел, где можно зафиксировать **фактическую** отказоустойчивость, а не «как должно быть по книжке».

Ниже — набор **read-only** команд/шаблонов, чтобы собрать данные по:

* HA control-plane (`istiod`)
* HA gateway’ев (`istio-ingressgateway`, `istio-egressgateway`)
* sidecar-инжектору (webhook)
* сетевым зависимостям (DNS, PKI/IdP/tracing)

Везде буду использовать те же переменные:

```bash
CTX=your-cluster-context      # kube-context кластера
NS_ISTIO=istio-d              # namespace с control-plane
NS_GW=sm-gateways             # namespace с ingress/egress gateway
```

Добавляй `--context="$CTX"` в команды.

---

## 1. Control-plane HA (`istiod`)

### 1.1. Сколько реплик и как они размазаны по нодам

```bash
# Deployment istiod с количеством реплик и стратегией
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o wide

# Подробный YAML для документации
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o yaml \
  > cluster-$CTX-istiod-deploy.yaml

# Где реально крутятся поды istiod
kubectl --context="$CTX" get pods -n "$NS_ISTIO" -l app=istiod -o wide
```

**Объяснение:**

* `get deploy` покажет `DESIRED`/`CURRENT`/`READY` — отсюда берёшь факт `replicas: N`.
* `-o wide` и `get pods -o wide` покажут, на каких **нодах** висят Pod’ы — пригодится, чтобы описать «размазано по AZ/DC» в доке.
* YAML можно положить в артефакты, а в документацию — только выдержки (реплики, стратегия, `affinity`, `topologySpreadConstraints` и т.п.).

---

### 1.2. Проверить PodDisruptionBudget для `istiod`

```bash
# Все PDB в namespace istio-d
kubectl --context="$CTX" get pdb -n "$NS_ISTIO"

# Детали PDB для istiod
kubectl --context="$CTX" get pdb -n "$NS_ISTIO" -o yaml \
  > cluster-$CTX-istiod-pdb.yaml
```

**Объяснение:**

* В списке PDB увидишь, есть ли объект типа `istiod-pdb` и какие `minAvailable` / `maxUnavailable`.
* YAML пригодится, чтобы в документации честно написать:
  «Для istiod настроен PDB с `minAvailable: 1` (или другой параметр), что защищает нас от…».

Если PDB нет — это тоже важный факт для раздела *Failure model*.

---

### 1.3. Есть ли `topologySpreadConstraints` / `affinity` у `istiod`

```bash
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o json \
  | jq '.spec.template.spec | {affinity, topologySpreadConstraints}'
```

> Если `jq` нельзя — просто смотри в `cluster-$CTX-istiod-deploy.yaml`.

**Объяснение:**

* Показывает, есть ли:

  * `podAntiAffinity` (например, не класть все istiod на одну ноду),
  * `topologySpreadConstraints` (равномерно по зонам/нодам).
* Это конкретные значения, которые можно перечислить в доке:
  «istiod имеет PodAntiAffinity по label’у X, spread по topology key `topology.kubernetes.io/zone`».

---

### 1.4. Leader election (Lease)

Если в control-plane есть компоненты с лидером (в основном это отдельные контроллеры, вебхуки и т.п.):

```bash
# Все Lease-объекты в кластере
kubectl --context="$CTX" get leases -A

# Lease, относящиеся к Istio (примерный фильтр по имени)
kubectl --context="$CTX" get leases -A | grep -i istio
```

**Объяснение:**

* Если есть контроллеры Istio (или рядом с ним) с leader-election, они будут создаваться как `Lease` в API-группе `coordination.k8s.io`.
* Для документации: «Компонент X использует leader election через Lease Y в namespace Z».

---

## 2. Gateway HA (`istio-ingressgateway`, `istio-egressgateway`)

### 2.1. Реплики и развёртывание ingress/egress gateway

```bash
# Ingress gateway
kubectl --context="$CTX" get deploy istio-ingressgateway -n "$NS_GW" -o wide
kubectl --context="$CTX" get deploy istio-ingressgateway -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-ingress-deploy.yaml

# Egress gateway
kubectl --context="$CTX" get deploy istio-egressgateway -n "$NS_GW" -o wide
kubectl --context="$CTX" get deploy istio-egressgateway -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-egress-deploy.yaml

# Фактические поды и ноды
kubectl --context="$CTX" get pods -n "$NS_GW" -o wide | grep istio-ingressgateway
kubectl --context="$CTX" get pods -n "$NS_GW" -o wide | grep istio-egressgateway
```

**Объяснение:**

* Узнаешь:

  * `replicas:` (есть ли ≥2 для HA),
  * где стоят поды (размазаны ли по нодам),
  * есть ли `affinity`/`topologySpreadConstraints` на gateways — смотришь в YAML так же, как для `istiod`.

---

### 2.2. PodDisruptionBudget для gateway’ев

```bash
kubectl --context="$CTX" get pdb -n "$NS_GW"

kubectl --context="$CTX" get pdb -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-gateways-pdb.yaml
```

**Объяснение:**

* В списке PDB: есть ли отдельные PDB для ingress/egress gateway.
* В YAML — фактические `minAvailable` / `maxUnavailable`.
  В документацию можно написать: «Для ingress/egress gateway настроены PDB таким образом, что при drain ноды всегда остаётся ≥1 Pod на кластере».

---

### 2.3. Проверить health-endpoints для L4 LB (порт 15021, /healthz/ready)

```bash
# Посмотреть readinessProbe/livenessProbe в deployment'ах gateways
kubectl --context="$CTX" get deploy istio-ingressgateway -n "$NS_GW" -o json \
  | jq '.spec.template.spec.containers[] | select(.name=="istio-proxy") | {name, readinessProbe, livenessProbe}'

kubectl --context="$CTX" get deploy istio-egressgateway -n "$NS_GW" -o json \
  | jq '.spec.template.spec.containers[] | select(.name=="istio-proxy") | {name, readinessProbe, livenessProbe}'
```

**Объяснение:**

* Здесь ты увидишь фактический `httpGet`/`port`/`path` для health-checks — обычно это `port: 15021, path: /healthz/ready`.
* Эти значения можно напрямую включить в раздел: «L4 LB health-checks».

Если `jq` нельзя — то же самое руками смотришь в YAML деплойментов.

---

### 2.4. Тип сервисов gateway’ев и порты (для bare-metal LB / NodePort)

```bash
kubectl --context="$CTX" get svc -n "$NS_GW" | grep istio-ingressgateway
kubectl --context="$CTX" get svc -n "$NS_GW" | grep istio-egressgateway

kubectl --context="$CTX" get svc istio-ingressgateway -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-ingress-svc.yaml

kubectl --context="$CTX" get svc istio-egressgateway -n "$NS_GW" -o yaml \
  > cluster-$CTX-istio-egress-svc.yaml
```

**Объяснение:**

* Из `spec.type` видишь:

  * `LoadBalancer` → балансировка напрямую,
  * `NodePort` → внешний HAProxy/keepalived/Nginx работает поверх NodePort’ов.
* Из `spec.ports[]` можно взять фактические: `80`, `443`, `15443`, `15021`, `15090`, etc.

---

## 3. Sidecars и admission webhook (инжекция)

### 3.1. Проверить, какие namespaces включены в auto-injection

```bash
# Все namespaces с label'ами istio-injection или ревизиями istio.io/rev
kubectl --context="$CTX" get ns --show-labels \
  | egrep 'istio-injection=|istio.io/rev='
```

**Объяснение:**

* По этому выводу можно задокументировать: «Sidecar-инжекция включена для namespaces: A, B, C…».
* Это помогает описать, какая часть нагрузок реально под защитой mesh.

---

### 3.2. Найти MutatingWebhookConfiguration sidecar-инжектора

```bash
kubectl --context="$CTX" get mutatingwebhookconfiguration \
  | grep -i istio
```

Чаще всего это что-то вроде `istio-sidecar-injector` или `istio-revisioned-webhook`.

```bash
WEBHOOK=$(kubectl --context="$CTX" get mutatingwebhookconfiguration \
  | awk '/istio/ {print $1; exit}')

kubectl --context="$CTX" get mutatingwebhookconfiguration "$WEBHOOK" -o yaml \
  > cluster-$CTX-istio-sidecar-webhook.yaml
```

**Объяснение:**

* В YAML видно:

  * `clientConfig.service` — на какой сервис ходит API-сервер (обычно `istiod.<ns>:443`),
  * `failurePolicy` — `Fail` или `Ignore`,
  * `timeoutSeconds` — важно для отказоустойчивости (длительные подвисания вебхука),
  * `namespaceSelector` / `objectSelector` — какие namespaces и Pods затрагиваются.
* Это напрямую ложится в текст: «Admission webhook для sidecar-инжекции имеет failurePolicy=Fail, timeoutSeconds=10, работает через сервис istiod…».

---

### 3.3. PDB и ресурсы для вебхука (по сути — для `istiod`)

Так как sidecar-инжектор сейчас, как правило, часть `istiod`, тут фактически PDB/ресурсы те же, что и у control-plane (см. раздел 1):

* PDB `istiod` (см. 1.2).
* `resources.requests/limits` у контейнера `istio-discovery` в Deployment `istiod`.

```bash
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o json \
  | jq '.spec.template.spec.containers[] | select(.name=="discovery") | {name, resources}'
```

**Объяснение:**

* Показывает, насколько «жирно» выделены ресурсы для вебхука и control-plane, и есть ли риск, что его легко вытеснит kube-scheduler / eviction-manager.

---

## 4. Сетевые отказовые сценарии (DNS, PKI/IdP/tracing)

Здесь уже не всё можно проверить строго read-only, но можно:

### 4.1. DNS (CoreDNS/kube-dns) — базовая проверка

```bash
# Статус DNS pod'ов
kubectl --context="$CTX" get pods -n kube-system -o wide \
  | egrep 'coredns|kube-dns'

# Сервис DNS
kubectl --context="$CTX" get svc -n kube-system \
  | egrep 'coredns|kube-dns'
```

**Объяснение:**

* Эти команды не проверяют отказоустойчивость «под нагрузкой», но позволяют задокументировать:

  * сколько Pod’ов DNS,
  * есть ли у них аннотации/affinity,
  * какой тип сервиса (`ClusterIP` с `clusterIP: X`) и т.п.

---

### 4.2. Проверить, как Istio зависит от DNS/PKI/IdP/tracing по конфигу, а не тестами

Здесь разумно сделать именно **инвентаризацию зависимостей**:

1. **ServiceEntry / VirtualService** для egress к PKI/IdP/tracing-backend’ам (частично уже делали в предыдущем разделе):

   ```bash
   kubectl --context="$CTX" get serviceentry -A -o yaml \
     > cluster-$CTX-istio-serviceentries.yaml
   ```

2. **DestinationRule / AuthorizationPolicy** для этих ServiceEntry:

   ```bash
   kubectl --context="$CTX" get destinationrule -A -o yaml \
     > cluster-$CTX-istio-destrules.yaml

   kubectl --context="$CTX" get authorizationpolicy -A -o yaml \
     > cluster-$CTX-istio-authzpolicies.yaml
   ```

3. **Istio meshConfig / tracingConfig**, если они заданы в `IstioOperator` или configmap’е:

   ```bash
   # Если используете IstioOperator CR
   kubectl --context="$CTX" get istiooperator -A -o yaml \
     > cluster-$CTX-istio-operators.yaml

   # Если конфиг лежит в ConfigMap (частый вариант)
   kubectl --context="$CTX" get configmap -n "$NS_ISTIO" \
     | grep -i istio

   kubectl --context="$CTX" get configmap istio -n "$NS_ISTIO" -o yaml \
     > cluster-$CTX-istio-configmap.yaml 2>/dev/null || true
   ```

**Объяснение:**

* Из этих YAML’ов можно вывести:
  «При недоступности X (tracing backend) Istio просто не сможет отдавать трейсы, но трафик продолжит ходить, так как …» — это уже текстовое заключение на основе конфигурации.

---

## 5. Сбор всего в один скрипт (опционально)

Мини-скрипт, который собирает все артефакты только по Istio-HA:

```bash
#!/usr/bin/env bash
set -euo pipefail

CTX="$1"
NS_ISTIO=istio-d
NS_GW=sm-gateways

OUT_DIR="cluster-$CTX-ha-istio"
mkdir -p "$OUT_DIR"

echo "=== Collecting Istio HA config for context: $CTX ==="

# istiod: deploy + pods + pdb
kubectl --context="$CTX" get deploy istiod -n "$NS_ISTIO" -o yaml \
  > "$OUT_DIR/istiod-deploy.yaml"
kubectl --context="$CTX" get pods -n "$NS_ISTIO" -l app=istiod -o wide \
  > "$OUT_DIR/istiod-pods.txt"
kubectl --context="$CTX" get pdb -n "$NS_ISTIO" \
  > "$OUT_DIR/istiod-pdb-list.txt"
kubectl --context="$CTX" get pdb -n "$NS_ISTIO" -o yaml \
  > "$OUT_DIR/istiod-pdb.yaml" 2>/dev/null || true

# Gateways: deploy + pods + pdb + svc
for GW in istio-ingressgateway istio-egressgateway; do
  kubectl --context="$CTX" get deploy "$GW" -n "$NS_GW" -o yaml \
    > "$OUT_DIR/$GW-deploy.yaml" 2>/dev/null || true
  kubectl --context="$CTX" get pods -n "$NS_GW" -o wide \
    | grep "$GW" > "$OUT_DIR/$GW-pods.txt" 2>/dev/null || true
  kubectl --context="$CTX" get pdb -n "$NS_GW" \
    > "$OUT_DIR/$GW-pdb-list.txt" 2>/dev/null || true
  kubectl --context="$CTX" get svc "$GW" -n "$NS_GW" -o yaml \
    > "$OUT_DIR/$GW-svc.yaml" 2>/dev/null || true
done

# Sidecar injection webhook
kubectl --context="$CTX" get mutatingwebhookconfiguration \
  > "$OUT_DIR/mutatingwebhooks.txt"
kubectl --context="$CTX" get mutatingwebhookconfiguration -o yaml \
  > "$OUT_DIR/mutatingwebhooks.yaml"

# Namespaces with istio-injection/revision labels
kubectl --context="$CTX" get ns --show-labels \
  > "$OUT_DIR/namespaces-with-labels.txt"
```

**Объяснение:**

* Скрипт **ничего не меняет** в кластере; только читает конфиг и складывает в файловую структуру.
* Потом ты спокойно, уже оффлайн, просматриваешь YAML/тексты и руками переписываешь ключевые моменты в документацию (реплики, PDB, spread, health-checks и т.п.).

---

Если хочешь, можешь взять вывод реального кластера (обезличить имена/домены) и принести сюда — я помогу на основе этих YAML/`get`-выводов сформулировать уже **текстовую** часть `Failure model & HA strategy` конкретно под вашу фактическую конфигурацию.
